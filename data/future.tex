\chapter{总结与展望}
\section{总结}
本文从模型结构、学习框架、数据集构建的角度提出了提升聊天机器人对于用户的情感、对话语义，以及对话中可能存在的不安全行为的理解力的改进，并且本文中详尽的实验证明了提出的改进的有效性，具体而言可以归纳为以下几点：
\begin{enumerate}
		\item 为了缓解对话情绪分析中的上下文稀疏和上下文冗余问题，我们提出了一种新的对话情绪分析方法，能够从可变长度的上下文中识别说话者的情绪。我们的方法中包含两个新的模块：1) 两个说话者感知单元，它显式地模拟说话者内部和说话者之间的依赖关系以提炼的对话上下文表示 2) 一个 top-k 规范化层，它确定最合适预测说话者情绪的对话上下文窗口。我们精心设计的实验和消融研究表明，我们的方法可以有效缓解对话情绪分析中的上下文缺失和上下文冗余问题，同时在三个公共数据集上实现具有竞争力的性能。
		      
		\item 为了缓解对话理解任务缺少训练数据的问题，我们提出了友邻训练，第一个跨任务自训练框架，它利用友邻任务的监督来更好地选择伪标签。我们在对话语义角色标注和对话重写之间实现了友邻训练并且领域泛化和少样本学习场景的实验证明了友邻训练的前景——友邻学习大幅度优于之前的经典或最先进的半监督方法。
		      
		\item 为了减少聊天机器人的不安全行为，我们提出了 \data{}，第一个具有对话安全综合标注的大规模数据集。 \data{} 标注了不安全跨度以回答为什么话语不安全，并提供安全的替代响应来替换不安全的响应。 我们的实验和分析表明，\data{} 有效地推进了对话不安全行为的解释和解毒。
  
\end{enumerate}
        
\section{未来展望}
虽然本文中提出的改进方法能够提升对应的任务模型的性能，但是最近ChatGPT在各项任务上都表现出了优异的性能，使得各项任务模型有着大统一的趋势，其中包括自然语言理解~\cite{chen2023robust}、机器翻译~\cite{bang2023multitask}、信息抽取~\cite{wei2023zero}以及文本纠错~\cite{wuchatgpt}等任务。未来还会考虑从以下的一些方向尝试改进：
\begin{enumerate}
    \item 虽然ChatGPT能够作为一个强力的日常辅助工具，但是其在理解用户情感并且调节用户情绪的功能上还有待提升。未来可以尝试在提示学习，参数高效微调的方向上融入相关的情感数据，使得其能够更好地在和用户交谈的时候做出更让人接受的回答。
    \item 由于ChatGPT的训练数据中不可避免地存在有毒的语料，所以其也不可避免地会学习到一些不安全的行为。虽然本文构建的\data{}数据集能够有效地降低对话中的不安全行为，但是要想大规模语言模型的毒害性尽可能地降低，需要更多的数据清洗，不安全行为检测，以及模型优化的方法。
\end{enumerate}