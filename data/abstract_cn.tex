% 中英文摘要
\begin{cabstract}
如何在对话中识别和理解说话者的情绪、话语中的共指和省略以及用户的不安全行为是人性化聊天机器人的关键能力~\cite{cn1,cn2}。本论文着重于这三个部分，并通过设计新的模型架构、新的学习框架或构建新的数据集来提升特定任务模型的性能。

具体而言，本文的研究内容主要包含三个章节：

\begin{enumerate}

    \item 基于变长上下文的对话情绪识别。现有的对话情绪识别方法使用固定的上下文窗口来识别说话者的情绪，这可能导致关键上下文信息的缺乏或冗余上下文信息的干扰。作为回应，本文探讨了可变长度上下文的好处，并提出了一种更有效的对话情绪识别方法，能够在预测不同话语的情绪时利用不同的上下文窗口。该方法包含两个新模块以实现可变长度上下文：1) 两个说话者感知单元，它显式地模拟说话者内部和说话者之间的依赖关系以提炼的对话上下文表示；2) 一个 top-k 规范化层，它确定最合适预测说话者情绪的对话上下文窗口。实验结果表明，该方法在三个公共数据集上优于几个强大的基线方法。

    \item 基于友邻学习的对话语义理解。目前的⾃训练方法，如标准⾃训练、协同训练、三重训练等，通常侧重于利用输入特征、模型架构和训练过程的差异提高模型在单个任务上的性能。⾃然语⾔处理中的许多任务都是关于语⾔的不同但相关的⽅⾯，并且为⼀项任务训练的模型可以成为其他相关任务的好⽼师。本文提出了友邻训练，一个跨任务的⾃训练框架，其中经过训练以执行不同任务的模型基于迭代训练、伪标签生成和再训练的过程，目的是相互帮助进而更好地选择伪标签。本文将友邻训练应用于两个对话理解任务，分别是对话语义角色标注和对话重写，实验结果表明与强基线相比，使⽤友邻训练框架训练的模型达到了最佳的性能，提升了模型理解对话语义的能力。

    \item 基于\data{}的对话不安全行为理解。不安全行为的普遍存在是开放域端到端对话系统或聊天机器人面临的主要挑战之一，例如有毒语言和有害建议。然而，现有的对话数据集没有提供足够的注释来解释和纠正这种不安全的行为。本文构建了一个名为 \data{} 的新数据集，用于研究对话安全性：（1）除了话语级别的安全标签外，\data{} 还提供了话语中的不安全跨度，这些信息能够指示哪些词造成检测到的不安全行为； (2) \data{} 提供安全的替代回复以在检测到不安全行为时继续对话，将对话引导到文明的轨迹。由于 \data{} 有全面的标注，本文对三个强大的模型进行了基准测试，以缓解会话不安全行为，包括检测不安全话语的检查器、提取不安全跨度的标记器以及将不安全响应转换为安全版本的重写器。此外，本文还探索了将模型结合起来用于解释不安全行为和为聊天机器人排毒所带来的巨大好处。实验结果表明，检测到的不安全行为可以用不安全的跨度很好地解释，并且流行的聊天机器人可以在很大程度上被解毒。
    
\end{enumerate}
	
	综上，本文首先提出了一种从可变长度的上下文中识别说话者情绪的新方法，然后将跨任务监督注入自训练以选择高质量的伪标签来训练更好的对话语义角色标签和对话重写的模型，最后构建一个具有全面标注的大规模数据集，以帮助理解和纠正对话的不安全行为。
	
	\vskip 21bp
	{\heiti\zihao{-4} 关键词：}
	对话情绪识别，
        对话语义，
        对话安全，
        聊天机器人
	
	\begin{flushright}
		作者：张冕
		
		指导老师：周夏冰、陈文亮
		
	\end{flushright}
\end{cabstract}
